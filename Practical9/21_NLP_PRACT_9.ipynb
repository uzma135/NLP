{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21_NLP_PRACT_9.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Implement Naive Bayes classifier"],"metadata":{"id":"Ijw3prPWOD-s"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB5KM_QaCX4i","executionInfo":{"status":"ok","timestamp":1649056171847,"user_tz":-330,"elapsed":15296,"user":{"displayName":"21_uzma _Siddiqui","userId":"04969838635475578275"}},"outputId":"2a1fb249-4819-4c2f-ea70-5b5c5da80e06"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n","['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n","              precision    recall  f1-score   support\n","\n","         ham       0.99      0.99      0.99      1448\n","        spam       0.92      0.93      0.92       224\n","\n","    accuracy                           0.98      1672\n","   macro avg       0.95      0.96      0.96      1672\n","weighted avg       0.98      0.98      0.98      1672\n","\n","accuracy_score:  0.979066985645933\n"]}],"source":["#pip install pandas\n","#pip install sklearn\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","sms_data = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","stemming = PorterStemmer()\n","corpus = []\n","for i in range (0,len(sms_data)):\n","  s1 = re.sub('[^a-zA-Z]',repl = ' ',string = sms_data['v2'][i])\n","  s1.lower()\n","  s1 = s1.split()\n","  s1 = [stemming.stem(word) for word in s1 if word not in\n","set(stopwords.words('english'))]\n","  s1 = ' '.join(s1)\n","  corpus.append(s1)\n","from sklearn.feature_extraction.text import CountVectorizer\n","countvectorizer =CountVectorizer()\n","x = countvectorizer.fit_transform(corpus).toarray()\n","print(x)\n","y = sms_data['v1'].values\n","print(y)\n","from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,\n","stratify=y,random_state=2)\n","#Multinomial Na√Øve Bayes.\n","from sklearn.naive_bayes import MultinomialNB\n","multinomialnb = MultinomialNB()\n","multinomialnb.fit(x_train,y_train)\n","# Predicting on test data:\n","y_pred = multinomialnb.predict(x_test)\n","print(y_pred)\n","#Results of our Models\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import accuracy_score\n","print(classification_report(y_test,y_pred))\n","print(\"accuracy_score: \",accuracy_score(y_test,y_pred))"]}]}